2024-11-22 16:22:46:INFO:Start running misa...
2024-11-22 16:22:46:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:22:46:INFO:Let's use 1 GPUs!
2024-11-22 16:35:34:INFO:Start running misa...
2024-11-22 16:35:34:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:35:34:INFO:Let's use 1 GPUs!
2024-11-22 16:35:34:INFO:train samples: (1368,)
2024-11-22 16:35:35:INFO:valid samples: (456,)
2024-11-22 16:35:35:INFO:test samples: (457,)
2024-11-22 16:38:20:INFO:Start running misa...
2024-11-22 16:38:20:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:38:20:INFO:Let's use 1 GPUs!
2024-11-22 16:38:20:INFO:train samples: (1368,)
2024-11-22 16:38:21:INFO:valid samples: (456,)
2024-11-22 16:38:21:INFO:test samples: (457,)
2024-11-22 16:38:21:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:38:22:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:38:23:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:38:23:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:38:24:INFO:The model has 123933167 trainable parameters
2024-11-22 16:43:19:INFO:Start running misa...
2024-11-22 16:43:19:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:43:19:INFO:Let's use 1 GPUs!
2024-11-22 16:43:20:INFO:train samples: (1368,)
2024-11-22 16:43:20:INFO:valid samples: (456,)
2024-11-22 16:43:21:INFO:test samples: (457,)
2024-11-22 16:43:21:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:43:21:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:43:21:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:43:22:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:43:23:INFO:The model has 123933167 trainable parameters
2024-11-22 16:44:31:INFO:Start running misa...
2024-11-22 16:44:31:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:44:31:INFO:Let's use 1 GPUs!
2024-11-22 16:44:31:INFO:train samples: (1368,)
2024-11-22 16:44:32:INFO:valid samples: (456,)
2024-11-22 16:44:32:INFO:test samples: (457,)
2024-11-22 16:44:32:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:44:32:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:44:33:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:44:33:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:44:34:INFO:The model has 123933167 trainable parameters
2024-11-22 16:46:02:INFO:Start running misa...
2024-11-22 16:46:02:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:46:02:INFO:Let's use 1 GPUs!
2024-11-22 16:46:03:INFO:train samples: (1368,)
2024-11-22 16:46:03:INFO:valid samples: (456,)
2024-11-22 16:46:04:INFO:test samples: (457,)
2024-11-22 16:46:04:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:46:04:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:46:04:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:46:05:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:46:06:INFO:The model has 123933167 trainable parameters
2024-11-22 16:47:45:INFO:Start running misa...
2024-11-22 16:47:45:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:47:45:INFO:Let's use 1 GPUs!
2024-11-22 16:47:46:INFO:train samples: (1368,)
2024-11-22 16:47:46:INFO:valid samples: (456,)
2024-11-22 16:47:47:INFO:test samples: (457,)
2024-11-22 16:47:47:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:47:47:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:47:47:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:47:48:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:47:49:INFO:The model has 123933167 trainable parameters
2024-11-22 16:50:29:INFO:Start running misa...
2024-11-22 16:50:29:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:50:29:INFO:Let's use 1 GPUs!
2024-11-22 16:50:29:INFO:train samples: (1368,)
2024-11-22 16:50:29:INFO:valid samples: (456,)
2024-11-22 16:50:30:INFO:test samples: (457,)
2024-11-22 16:50:30:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:50:30:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:50:31:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:50:31:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:50:32:INFO:The model has 123933167 trainable parameters
2024-11-22 16:50:56:INFO:Start running misa...
2024-11-22 16:50:56:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:50:56:INFO:Let's use 1 GPUs!
2024-11-22 16:50:56:INFO:train samples: (1368,)
2024-11-22 16:50:57:INFO:valid samples: (456,)
2024-11-22 16:50:57:INFO:test samples: (457,)
2024-11-22 16:50:57:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:50:58:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:50:58:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:50:58:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:50:59:INFO:The model has 123933167 trainable parameters
2024-11-22 16:51:15:INFO:Start running misa...
2024-11-22 16:51:15:INFO:<Storage{'is_tune': False, 'train_mode': 'classification', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 16:51:15:INFO:Let's use 1 GPUs!
2024-11-22 16:51:15:INFO:train samples: (1368,)
2024-11-22 16:51:16:INFO:valid samples: (456,)
2024-11-22 16:51:16:INFO:test samples: (457,)
2024-11-22 16:51:16:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 16:51:17:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 16:51:18:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:51:18:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 16:51:19:INFO:The model has 123933167 trainable parameters
2024-11-22 16:51:27:INFO:TRAIN-(False) [1/1/False] >> loss: 3.0576  Has0_acc_2: 0.6367  Has0_F1_score: 0.5944  Non0_acc_2: 0.5426  Non0_F1_score: 0.4668  Acc_3: 0.4803  F1_score_3: 0.3934 
2024-11-22 16:51:28:INFO:VAL-(False) >>  Has0_acc_2: 0.6952  Has0_F1_score: 0.5702  Non0_acc_2: 0.6408  Non0_F1_score: 0.5006  Acc_3: 0.5439  F1_score_3: 0.3832  Loss: 1.0024 
2024-11-22 16:51:36:INFO:TRAIN-(False) [1/2/False] >> loss: 2.3842  Has0_acc_2: 0.6944  Has0_F1_score: 0.5700  Non0_acc_2: 0.6391  Non0_F1_score: 0.4986  Acc_3: 0.5431  F1_score_3: 0.3831 
2024-11-22 16:51:37:INFO:VAL-(False) >>  Has0_acc_2: 0.6952  Has0_F1_score: 0.5702  Non0_acc_2: 0.6408  Non0_F1_score: 0.5006  Acc_3: 0.5439  F1_score_3: 0.3832  Loss: 0.9536 
2024-11-22 16:51:45:INFO:TRAIN-(False) [1/3/False] >> loss: 2.1519  Has0_acc_2: 0.6966  Has0_F1_score: 0.5827  Non0_acc_2: 0.6374  Non0_F1_score: 0.5002  Acc_3: 0.5482  F1_score_3: 0.3974 
2024-11-22 16:51:46:INFO:VAL-(False) >>  Has0_acc_2: 0.6952  Has0_F1_score: 0.5702  Non0_acc_2: 0.6408  Non0_F1_score: 0.5006  Acc_3: 0.5439  F1_score_3: 0.3832  Loss: 0.9446 
2024-11-22 17:05:27:INFO:Start running misa...
2024-11-22 17:05:27:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 17:05:27:INFO:Let's use 1 GPUs!
2024-11-22 17:05:27:INFO:train samples: (1368,)
2024-11-22 17:05:28:INFO:valid samples: (456,)
2024-11-22 17:05:28:INFO:test samples: (457,)
2024-11-22 17:05:28:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 17:05:29:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 17:05:29:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:05:29:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:05:30:INFO:The model has 123932397 trainable parameters
2024-11-22 17:05:38:INFO:TRAIN-(False) [1/1/False] >> loss: 2.6104  Mult_acc_2: 0.6148  Mult_acc_3: 0.4898  Mult_acc_5: 0.2010  F1_score: 0.5856  MAE: 0.6129  Corr: 0.0667 
2024-11-22 17:05:39:INFO:VAL-(False) >>  Mult_acc_2: 0.6952  Mult_acc_3: 0.5439  Mult_acc_5: 0.2193  F1_score: 0.5780  MAE: 0.5632  Corr: 0.3361  Loss: 0.4383 
2024-11-22 17:05:48:INFO:TRAIN-(False) [1/2/False] >> loss: 1.8442  Mult_acc_2: 0.7244  Mult_acc_3: 0.5278  Mult_acc_5: 0.2288  F1_score: 0.6914  MAE: 0.5362  Corr: 0.4361 
2024-11-22 17:05:49:INFO:VAL-(False) >>  Mult_acc_2: 0.7456  Mult_acc_3: 0.5175  Mult_acc_5: 0.1996  F1_score: 0.7309  MAE: 0.5129  Corr: 0.5097  Loss: 0.3660 
2024-11-22 17:05:57:INFO:TRAIN-(False) [1/3/False] >> loss: 1.5349  Mult_acc_2: 0.7785  Mult_acc_3: 0.6330  Mult_acc_5: 0.2807  F1_score: 0.7757  MAE: 0.4528  Corr: 0.6627 
2024-11-22 17:05:57:INFO:VAL-(False) >>  Mult_acc_2: 0.6754  Mult_acc_3: 0.5636  Mult_acc_5: 0.2061  F1_score: 0.6881  MAE: 0.5184  Corr: 0.5516  Loss: 0.3552 
2024-11-22 17:06:06:INFO:TRAIN-(False) [1/4/False] >> loss: 1.304  Mult_acc_2: 0.8173  Mult_acc_3: 0.7368  Mult_acc_5: 0.3779  F1_score: 0.8222  MAE: 0.3660  Corr: 0.7836 
2024-11-22 17:06:06:INFO:VAL-(False) >>  Mult_acc_2: 0.7325  Mult_acc_3: 0.6469  Mult_acc_5: 0.3377  F1_score: 0.7375  MAE: 0.4539  Corr: 0.5725  Loss: 0.3101 
2024-11-22 17:06:15:INFO:TRAIN-(False) [1/5/False] >> loss: 1.1003  Mult_acc_2: 0.8501  Mult_acc_3: 0.7822  Mult_acc_5: 0.4861  F1_score: 0.8539  MAE: 0.2846  Corr: 0.8590 
2024-11-22 17:06:15:INFO:VAL-(False) >>  Mult_acc_2: 0.6645  Mult_acc_3: 0.5746  Mult_acc_5: 0.2654  F1_score: 0.6778  MAE: 0.4954  Corr: 0.5652  Loss: 0.4019 
2024-11-22 17:06:22:INFO:TRAIN-(False) [2/6/False] >> loss: 0.9463  Mult_acc_2: 0.8787  Mult_acc_3: 0.8070  Mult_acc_5: 0.5724  F1_score: 0.8815  MAE: 0.2339  Corr: 0.9036 
2024-11-22 17:06:23:INFO:VAL-(False) >>  Mult_acc_2: 0.7171  Mult_acc_3: 0.6272  Mult_acc_5: 0.3421  F1_score: 0.7252  MAE: 0.4595  Corr: 0.5746  Loss: 0.3260 
2024-11-22 17:06:30:INFO:TRAIN-(False) [3/7/False] >> loss: 0.8394  Mult_acc_2: 0.8845  Mult_acc_3: 0.8275  Mult_acc_5: 0.6133  F1_score: 0.8877  MAE: 0.2068  Corr: 0.9256 
2024-11-22 17:06:31:INFO:VAL-(False) >>  Mult_acc_2: 0.7610  Mult_acc_3: 0.6382  Mult_acc_5: 0.3684  F1_score: 0.7617  MAE: 0.4537  Corr: 0.5501  Loss: 0.3424 
2024-11-22 17:06:39:INFO:TRAIN-(False) [4/8/False] >> loss: 0.7499  Mult_acc_2: 0.8925  Mult_acc_3: 0.8260  Mult_acc_5: 0.6689  F1_score: 0.8950  MAE: 0.1759  Corr: 0.9422 
2024-11-22 17:06:40:INFO:VAL-(False) >>  Mult_acc_2: 0.7434  Mult_acc_3: 0.6009  Mult_acc_5: 0.3202  F1_score: 0.7484  MAE: 0.4588  Corr: 0.5645  Loss: 0.3177 
2024-11-22 17:06:47:INFO:TRAIN-(False) [5/9/False] >> loss: 0.6711  Mult_acc_2: 0.8991  Mult_acc_3: 0.8311  Mult_acc_5: 0.6667  F1_score: 0.9015  MAE: 0.1744  Corr: 0.9485 
2024-11-22 17:06:48:INFO:VAL-(False) >>  Mult_acc_2: 0.7478  Mult_acc_3: 0.6447  Mult_acc_5: 0.3838  F1_score: 0.7476  MAE: 0.4524  Corr: 0.5593  Loss: 0.3379 
2024-11-22 17:06:55:INFO:TRAIN-(False) [6/10/False] >> loss: 0.6184  Mult_acc_2: 0.8962  Mult_acc_3: 0.8275  Mult_acc_5: 0.6791  F1_score: 0.8984  MAE: 0.1634  Corr: 0.9493 
2024-11-22 17:06:56:INFO:VAL-(False) >>  Mult_acc_2: 0.6623  Mult_acc_3: 0.5614  Mult_acc_5: 0.2588  F1_score: 0.6756  MAE: 0.4923  Corr: 0.5663  Loss: 0.4018 
2024-11-22 17:07:03:INFO:TRAIN-(False) [7/11/False] >> loss: 0.5857  Mult_acc_2: 0.8757  Mult_acc_3: 0.8143  Mult_acc_5: 0.6425  F1_score: 0.8786  MAE: 0.1928  Corr: 0.9302 
2024-11-22 17:07:04:INFO:VAL-(False) >>  Mult_acc_2: 0.7368  Mult_acc_3: 0.6184  Mult_acc_5: 0.3355  F1_score: 0.7425  MAE: 0.4463  Corr: 0.5802  Loss: 0.3299 
2024-11-22 17:07:11:INFO:TRAIN-(False) [8/12/False] >> loss: 0.5405  Mult_acc_2: 0.8794  Mult_acc_3: 0.8209  Mult_acc_5: 0.6411  F1_score: 0.8827  MAE: 0.1870  Corr: 0.9370 
2024-11-22 17:07:12:INFO:VAL-(False) >>  Mult_acc_2: 0.6623  Mult_acc_3: 0.5768  Mult_acc_5: 0.2873  F1_score: 0.6756  MAE: 0.4788  Corr: 0.5860  Loss: 0.3452 
2024-11-22 17:08:37:INFO:Start running misa...
2024-11-22 17:08:37:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 17:08:37:INFO:Let's use 1 GPUs!
2024-11-22 17:08:37:INFO:train samples: (1368,)
2024-11-22 17:08:38:INFO:valid samples: (456,)
2024-11-22 17:08:38:INFO:test samples: (457,)
2024-11-22 17:08:38:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 17:08:39:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 17:08:39:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:08:39:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:08:40:INFO:The model has 123932397 trainable parameters
2024-11-22 17:08:48:INFO:TRAIN-(False) [1/1/False] >> loss: 2.6104  Mult_acc_2: 0.6148  Mult_acc_3: 0.4898  Mult_acc_5: 0.2010  F1_score: 0.5856  MAE: 0.6129  Corr: 0.0667 
2024-11-22 17:08:48:INFO:VAL-(False) >>  Mult_acc_2: 0.6952  Mult_acc_3: 0.5439  Mult_acc_5: 0.2193  F1_score: 0.5780  MAE: 0.5632  Corr: 0.3361  Loss: 0.4383 
2024-11-22 17:08:56:INFO:TRAIN-(False) [1/2/False] >> loss: 1.8442  Mult_acc_2: 0.7244  Mult_acc_3: 0.5278  Mult_acc_5: 0.2288  F1_score: 0.6914  MAE: 0.5362  Corr: 0.4361 
2024-11-22 17:08:57:INFO:VAL-(False) >>  Mult_acc_2: 0.7456  Mult_acc_3: 0.5175  Mult_acc_5: 0.1996  F1_score: 0.7309  MAE: 0.5129  Corr: 0.5097  Loss: 0.3660 
2024-11-22 17:09:05:INFO:TRAIN-(False) [1/3/False] >> loss: 1.5349  Mult_acc_2: 0.7785  Mult_acc_3: 0.6330  Mult_acc_5: 0.2807  F1_score: 0.7757  MAE: 0.4528  Corr: 0.6627 
2024-11-22 17:09:06:INFO:VAL-(False) >>  Mult_acc_2: 0.6754  Mult_acc_3: 0.5636  Mult_acc_5: 0.2061  F1_score: 0.6881  MAE: 0.5184  Corr: 0.5516  Loss: 0.3552 
2024-11-22 17:09:14:INFO:TRAIN-(False) [1/4/False] >> loss: 1.304  Mult_acc_2: 0.8173  Mult_acc_3: 0.7368  Mult_acc_5: 0.3779  F1_score: 0.8222  MAE: 0.3660  Corr: 0.7836 
2024-11-22 17:09:15:INFO:VAL-(False) >>  Mult_acc_2: 0.7325  Mult_acc_3: 0.6469  Mult_acc_5: 0.3377  F1_score: 0.7375  MAE: 0.4539  Corr: 0.5725  Loss: 0.3101 
2024-11-22 17:09:23:INFO:TRAIN-(False) [1/5/False] >> loss: 1.1003  Mult_acc_2: 0.8501  Mult_acc_3: 0.7822  Mult_acc_5: 0.4861  F1_score: 0.8539  MAE: 0.2846  Corr: 0.8590 
2024-11-22 17:09:24:INFO:VAL-(False) >>  Mult_acc_2: 0.6645  Mult_acc_3: 0.5746  Mult_acc_5: 0.2654  F1_score: 0.6778  MAE: 0.4954  Corr: 0.5652  Loss: 0.4019 
2024-11-22 17:09:31:INFO:TRAIN-(False) [2/6/False] >> loss: 0.9463  Mult_acc_2: 0.8787  Mult_acc_3: 0.8070  Mult_acc_5: 0.5724  F1_score: 0.8815  MAE: 0.2339  Corr: 0.9036 
2024-11-22 17:09:32:INFO:VAL-(False) >>  Mult_acc_2: 0.7171  Mult_acc_3: 0.6272  Mult_acc_5: 0.3421  F1_score: 0.7252  MAE: 0.4595  Corr: 0.5746  Loss: 0.3260 
2024-11-22 17:09:39:INFO:TRAIN-(False) [3/7/False] >> loss: 0.8394  Mult_acc_2: 0.8845  Mult_acc_3: 0.8275  Mult_acc_5: 0.6133  F1_score: 0.8877  MAE: 0.2068  Corr: 0.9256 
2024-11-22 17:09:40:INFO:VAL-(False) >>  Mult_acc_2: 0.7610  Mult_acc_3: 0.6382  Mult_acc_5: 0.3684  F1_score: 0.7617  MAE: 0.4537  Corr: 0.5501  Loss: 0.3424 
2024-11-22 17:09:47:INFO:TRAIN-(False) [4/8/False] >> loss: 0.7499  Mult_acc_2: 0.8925  Mult_acc_3: 0.8260  Mult_acc_5: 0.6689  F1_score: 0.8950  MAE: 0.1759  Corr: 0.9422 
2024-11-22 17:09:48:INFO:VAL-(False) >>  Mult_acc_2: 0.7434  Mult_acc_3: 0.6009  Mult_acc_5: 0.3202  F1_score: 0.7484  MAE: 0.4588  Corr: 0.5645  Loss: 0.3177 
2024-11-22 17:09:55:INFO:TRAIN-(False) [5/9/False] >> loss: 0.6711  Mult_acc_2: 0.8991  Mult_acc_3: 0.8311  Mult_acc_5: 0.6667  F1_score: 0.9015  MAE: 0.1744  Corr: 0.9485 
2024-11-22 17:09:56:INFO:VAL-(False) >>  Mult_acc_2: 0.7478  Mult_acc_3: 0.6447  Mult_acc_5: 0.3838  F1_score: 0.7476  MAE: 0.4524  Corr: 0.5593  Loss: 0.3379 
2024-11-22 17:10:03:INFO:TRAIN-(False) [6/10/False] >> loss: 0.6184  Mult_acc_2: 0.8962  Mult_acc_3: 0.8275  Mult_acc_5: 0.6791  F1_score: 0.8984  MAE: 0.1634  Corr: 0.9493 
2024-11-22 17:10:04:INFO:VAL-(False) >>  Mult_acc_2: 0.6623  Mult_acc_3: 0.5614  Mult_acc_5: 0.2588  F1_score: 0.6756  MAE: 0.4923  Corr: 0.5663  Loss: 0.4018 
2024-11-22 17:10:11:INFO:TRAIN-(False) [7/11/False] >> loss: 0.5857  Mult_acc_2: 0.8757  Mult_acc_3: 0.8143  Mult_acc_5: 0.6425  F1_score: 0.8786  MAE: 0.1928  Corr: 0.9302 
2024-11-22 17:10:11:INFO:VAL-(False) >>  Mult_acc_2: 0.7368  Mult_acc_3: 0.6184  Mult_acc_5: 0.3355  F1_score: 0.7425  MAE: 0.4463  Corr: 0.5802  Loss: 0.3299 
2024-11-22 17:10:19:INFO:TRAIN-(False) [8/12/False] >> loss: 0.5405  Mult_acc_2: 0.8794  Mult_acc_3: 0.8209  Mult_acc_5: 0.6411  F1_score: 0.8827  MAE: 0.1870  Corr: 0.9370 
2024-11-22 17:10:19:INFO:VAL-(False) >>  Mult_acc_2: 0.6623  Mult_acc_3: 0.5768  Mult_acc_5: 0.2873  F1_score: 0.6756  MAE: 0.4788  Corr: 0.5860  Loss: 0.3452 
2024-11-22 17:10:21:INFO:VAL-(False) >>  Mult_acc_2: 0.7812  Mult_acc_3: 0.6302  Mult_acc_5: 0.3676  F1_score: 0.7812  MAE: 0.4464  Corr: 0.5678  Loss: 0.3299 
2024-11-22 17:10:21:INFO:Results are added to results_copy/results\normals\sims-regression.csv...
2024-11-22 17:12:04:INFO:Start running misa...
2024-11-22 17:12:04:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosi', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\MOSI/Processed/unaligned_50.pkl', 'seq_lens': (50, 500, 375), 'feature_dims': (768, 5, 20), 'train_samples': 1284, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 16, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.2, 'reverse_grad_weight': 0.8, 'diff_weight': 0.1, 'sim_weight': 0.3, 'sp_weight': 1.0, 'recon_weight': 1.0, 'grad_clip': 0.8, 'weight_decay': 0.0, 'transformers': 'bert', 'pretrained': 'bert-base-uncased', 'seed': 1111}>
2024-11-22 17:12:04:INFO:Let's use 1 GPUs!
2024-11-22 17:12:08:INFO:train samples: (1284,)
2024-11-22 17:12:08:INFO:valid samples: (229,)
2024-11-22 17:12:08:INFO:test samples: (686,)
2024-11-22 17:12:08:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 17:12:08:DEBUG:https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 17:12:09:DEBUG:https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:12:10:DEBUG:https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:12:11:INFO:The model has 110620273 trainable parameters
2024-11-22 17:12:21:INFO:TRAIN-(False) [1/1/False] >> loss: 3.2609  Has0_acc_2: 0.6682  Has0_F1_score: 0.6555  Non0_acc_2: 0.6637  Non0_F1_score: 0.6506  Mult_acc_5: 0.2438  Mult_acc_7: 0.2430  MAE: 1.1610  Corr: 0.4330 
2024-11-22 17:12:22:INFO:VAL-(False) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8137  Non0_acc_2: 0.8426  Non0_F1_score: 0.8430  Mult_acc_5: 0.4105  Mult_acc_7: 0.3406  MAE: 0.9396  Corr: 0.7019  Loss: 1.4246 
2024-11-22 17:12:33:INFO:TRAIN-(False) [1/2/False] >> loss: 1.826  Has0_acc_2: 0.8380  Has0_F1_score: 0.8388  Non0_acc_2: 0.8570  Non0_F1_score: 0.8573  Mult_acc_5: 0.4276  Mult_acc_7: 0.3956  MAE: 0.7209  Corr: 0.8005 
2024-11-22 17:12:34:INFO:VAL-(False) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8141  Non0_acc_2: 0.8426  Non0_F1_score: 0.8434  Mult_acc_5: 0.4760  Mult_acc_7: 0.3886  MAE: 0.8388  Corr: 0.7445  Loss: 1.3440 
2024-11-22 17:12:45:INFO:TRAIN-(False) [1/3/False] >> loss: 1.2792  Has0_acc_2: 0.8762  Has0_F1_score: 0.8767  Non0_acc_2: 0.8993  Non0_F1_score: 0.8995  Mult_acc_5: 0.5405  Mult_acc_7: 0.4953  MAE: 0.5642  Corr: 0.8783 
2024-11-22 17:12:46:INFO:VAL-(False) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8093  Non0_acc_2: 0.8241  Non0_F1_score: 0.8205  Mult_acc_5: 0.4454  Mult_acc_7: 0.3537  MAE: 0.8537  Corr: 0.7589  Loss: 1.2726 
2024-11-22 17:12:57:INFO:TRAIN-(False) [1/4/False] >> loss: 0.9239  Has0_acc_2: 0.9112  Has0_F1_score: 0.9115  Non0_acc_2: 0.9285  Non0_F1_score: 0.9285  Mult_acc_5: 0.6075  Mult_acc_7: 0.5561  MAE: 0.4587  Corr: 0.9224 
2024-11-22 17:12:57:INFO:VAL-(False) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8097  Non0_acc_2: 0.8380  Non0_F1_score: 0.8388  Mult_acc_5: 0.4803  Mult_acc_7: 0.3930  MAE: 0.8070  Corr: 0.7790  Loss: 1.1586 
2024-11-22 17:13:09:INFO:TRAIN-(False) [1/5/False] >> loss: 0.689  Has0_acc_2: 0.9283  Has0_F1_score: 0.9285  Non0_acc_2: 0.9448  Non0_F1_score: 0.9448  Mult_acc_5: 0.6643  Mult_acc_7: 0.6153  MAE: 0.3913  Corr: 0.9443 
2024-11-22 17:13:10:INFO:VAL-(False) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8372  Non0_acc_2: 0.8472  Non0_F1_score: 0.8456  Mult_acc_5: 0.5022  Mult_acc_7: 0.4061  MAE: 0.7329  Corr: 0.7936  Loss: 1.0006 
2024-11-22 17:13:22:INFO:TRAIN-(False) [1/6/False] >> loss: 0.5177  Has0_acc_2: 0.9260  Has0_F1_score: 0.9263  Non0_acc_2: 0.9513  Non0_F1_score: 0.9513  Mult_acc_5: 0.7313  Mult_acc_7: 0.6783  MAE: 0.3249  Corr: 0.9615 
2024-11-22 17:13:22:INFO:VAL-(False) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8295  Non0_acc_2: 0.8472  Non0_F1_score: 0.8463  Mult_acc_5: 0.4891  Mult_acc_7: 0.3930  MAE: 0.7332  Corr: 0.7991  Loss: 0.9874 
2024-11-22 17:13:33:INFO:TRAIN-(False) [1/7/False] >> loss: 0.3823  Has0_acc_2: 0.9447  Has0_F1_score: 0.9448  Non0_acc_2: 0.9634  Non0_F1_score: 0.9634  Mult_acc_5: 0.7788  Mult_acc_7: 0.7259  MAE: 0.2676  Corr: 0.9750 
2024-11-22 17:13:34:INFO:VAL-(False) >>  Has0_acc_2: 0.8079  Has0_F1_score: 0.8092  Non0_acc_2: 0.8333  Non0_F1_score: 0.8336  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7329  Corr: 0.7927  Loss: 1.0373 
2024-11-22 17:13:44:INFO:TRAIN-(False) [2/8/False] >> loss: 0.3125  Has0_acc_2: 0.9564  Has0_F1_score: 0.9565  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8131  Mult_acc_7: 0.7625  MAE: 0.2412  Corr: 0.9800 
2024-11-22 17:13:44:INFO:VAL-(False) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8298  Non0_acc_2: 0.8472  Non0_F1_score: 0.8466  Mult_acc_5: 0.5109  Mult_acc_7: 0.4148  MAE: 0.7368  Corr: 0.7976  Loss: 1.0007 
2024-11-22 17:13:54:INFO:TRAIN-(False) [3/9/False] >> loss: 0.2787  Has0_acc_2: 0.9657  Has0_F1_score: 0.9658  Non0_acc_2: 0.9838  Non0_F1_score: 0.9838  Mult_acc_5: 0.8022  Mult_acc_7: 0.7477  MAE: 0.2375  Corr: 0.9807 
2024-11-22 17:13:55:INFO:VAL-(False) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8169  Non0_acc_2: 0.8380  Non0_F1_score: 0.8373  Mult_acc_5: 0.5284  Mult_acc_7: 0.4148  MAE: 0.7219  Corr: 0.8006  Loss: 1.0096 
2024-11-22 17:14:05:INFO:TRAIN-(False) [4/10/False] >> loss: 0.243  Has0_acc_2: 0.9579  Has0_F1_score: 0.9581  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8255  Mult_acc_7: 0.7866  MAE: 0.2147  Corr: 0.9838 
2024-11-22 17:14:05:INFO:VAL-(False) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8330  Non0_acc_2: 0.8519  Non0_F1_score: 0.8501  Mult_acc_5: 0.5197  Mult_acc_7: 0.4148  MAE: 0.7313  Corr: 0.8033  Loss: 1.0081 
2024-11-22 17:14:16:INFO:TRAIN-(False) [5/11/False] >> loss: 0.2133  Has0_acc_2: 0.9626  Has0_F1_score: 0.9627  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8489  Mult_acc_7: 0.8076  MAE: 0.1998  Corr: 0.9859 
2024-11-22 17:14:16:INFO:VAL-(False) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8225  Non0_acc_2: 0.8519  Non0_F1_score: 0.8524  Mult_acc_5: 0.5153  Mult_acc_7: 0.4323  MAE: 0.7256  Corr: 0.7993  Loss: 1.0081 
2024-11-22 17:14:26:INFO:TRAIN-(False) [6/12/False] >> loss: 0.215  Has0_acc_2: 0.9533  Has0_F1_score: 0.9534  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8100  Mult_acc_7: 0.7648  MAE: 0.2182  Corr: 0.9837 
2024-11-22 17:14:27:INFO:VAL-(False) >>  Has0_acc_2: 0.8297  Has0_F1_score: 0.8309  Non0_acc_2: 0.8565  Non0_F1_score: 0.8568  Mult_acc_5: 0.5328  Mult_acc_7: 0.4279  MAE: 0.7204  Corr: 0.8006  Loss: 0.9636 
2024-11-22 17:14:38:INFO:TRAIN-(False) [1/13/False] >> loss: 0.1942  Has0_acc_2: 0.9579  Has0_F1_score: 0.9581  Non0_acc_2: 0.9756  Non0_F1_score: 0.9756  Mult_acc_5: 0.8326  Mult_acc_7: 0.7905  MAE: 0.2041  Corr: 0.9857 
2024-11-22 17:14:38:INFO:VAL-(False) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8341  Non0_acc_2: 0.8519  Non0_F1_score: 0.8511  Mult_acc_5: 0.5284  Mult_acc_7: 0.4236  MAE: 0.7139  Corr: 0.8049  Loss: 1.0200 
2024-11-22 17:14:48:INFO:TRAIN-(False) [2/14/False] >> loss: 0.1891  Has0_acc_2: 0.9603  Has0_F1_score: 0.9603  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8178  Mult_acc_7: 0.7858  MAE: 0.2149  Corr: 0.9841 
2024-11-22 17:14:49:INFO:VAL-(False) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8388  Non0_acc_2: 0.8611  Non0_F1_score: 0.8607  Mult_acc_5: 0.5153  Mult_acc_7: 0.4279  MAE: 0.7003  Corr: 0.8091  Loss: 0.9163 
2024-11-22 17:15:00:INFO:TRAIN-(False) [1/15/False] >> loss: 0.1758  Has0_acc_2: 0.9572  Has0_F1_score: 0.9573  Non0_acc_2: 0.9862  Non0_F1_score: 0.9862  Mult_acc_5: 0.8357  Mult_acc_7: 0.7983  MAE: 0.1969  Corr: 0.9860 
2024-11-22 17:15:01:INFO:VAL-(False) >>  Has0_acc_2: 0.8384  Has0_F1_score: 0.8388  Non0_acc_2: 0.8611  Non0_F1_score: 0.8607  Mult_acc_5: 0.5459  Mult_acc_7: 0.4367  MAE: 0.7119  Corr: 0.8062  Loss: 0.9600 
2024-11-22 17:15:11:INFO:TRAIN-(False) [2/16/False] >> loss: 0.1709  Has0_acc_2: 0.9564  Has0_F1_score: 0.9565  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8427  Mult_acc_7: 0.8045  MAE: 0.2038  Corr: 0.9853 
2024-11-22 17:15:11:INFO:VAL-(False) >>  Has0_acc_2: 0.8210  Has0_F1_score: 0.8204  Non0_acc_2: 0.8426  Non0_F1_score: 0.8411  Mult_acc_5: 0.5415  Mult_acc_7: 0.4279  MAE: 0.7144  Corr: 0.8083  Loss: 0.9570 
2024-11-22 17:15:21:INFO:TRAIN-(False) [3/17/False] >> loss: 0.1597  Has0_acc_2: 0.9603  Has0_F1_score: 0.9604  Non0_acc_2: 0.9764  Non0_F1_score: 0.9764  Mult_acc_5: 0.8442  Mult_acc_7: 0.8123  MAE: 0.1989  Corr: 0.9864 
2024-11-22 17:15:22:INFO:VAL-(False) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8338  Non0_acc_2: 0.8565  Non0_F1_score: 0.8553  Mult_acc_5: 0.5284  Mult_acc_7: 0.4367  MAE: 0.7118  Corr: 0.8070  Loss: 0.9343 
2024-11-22 17:15:32:INFO:TRAIN-(False) [4/18/False] >> loss: 0.1512  Has0_acc_2: 0.9618  Has0_F1_score: 0.9619  Non0_acc_2: 0.9797  Non0_F1_score: 0.9797  Mult_acc_5: 0.8575  Mult_acc_7: 0.8263  MAE: 0.1968  Corr: 0.9865 
2024-11-22 17:15:33:INFO:VAL-(False) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8265  Non0_acc_2: 0.8519  Non0_F1_score: 0.8520  Mult_acc_5: 0.5066  Mult_acc_7: 0.4105  MAE: 0.7137  Corr: 0.8039  Loss: 0.9517 
2024-11-22 17:15:43:INFO:TRAIN-(False) [5/19/False] >> loss: 0.1442  Has0_acc_2: 0.9618  Has0_F1_score: 0.9620  Non0_acc_2: 0.9846  Non0_F1_score: 0.9846  Mult_acc_5: 0.8333  Mult_acc_7: 0.7928  MAE: 0.1912  Corr: 0.9873 
2024-11-22 17:15:43:INFO:VAL-(False) >>  Has0_acc_2: 0.8253  Has0_F1_score: 0.8269  Non0_acc_2: 0.8565  Non0_F1_score: 0.8570  Mult_acc_5: 0.5371  Mult_acc_7: 0.4410  MAE: 0.7239  Corr: 0.8084  Loss: 1.0323 
2024-11-22 17:15:53:INFO:TRAIN-(False) [6/20/False] >> loss: 0.1329  Has0_acc_2: 0.9681  Has0_F1_score: 0.9682  Non0_acc_2: 0.9886  Non0_F1_score: 0.9886  Mult_acc_5: 0.8536  Mult_acc_7: 0.8185  MAE: 0.1803  Corr: 0.9888 
2024-11-22 17:15:54:INFO:VAL-(False) >>  Has0_acc_2: 0.8166  Has0_F1_score: 0.8174  Non0_acc_2: 0.8426  Non0_F1_score: 0.8424  Mult_acc_5: 0.5109  Mult_acc_7: 0.4236  MAE: 0.7076  Corr: 0.8021  Loss: 0.9987 
2024-11-22 17:16:04:INFO:TRAIN-(False) [7/21/False] >> loss: 0.1183  Has0_acc_2: 0.9673  Has0_F1_score: 0.9674  Non0_acc_2: 0.9870  Non0_F1_score: 0.9870  Mult_acc_5: 0.8723  Mult_acc_7: 0.8442  MAE: 0.1649  Corr: 0.9906 
2024-11-22 17:16:04:INFO:VAL-(False) >>  Has0_acc_2: 0.8341  Has0_F1_score: 0.8352  Non0_acc_2: 0.8611  Non0_F1_score: 0.8613  Mult_acc_5: 0.5328  Mult_acc_7: 0.4279  MAE: 0.6999  Corr: 0.8052  Loss: 0.9541 
2024-11-22 17:16:15:INFO:TRAIN-(False) [8/22/False] >> loss: 0.1129  Has0_acc_2: 0.9735  Has0_F1_score: 0.9736  Non0_acc_2: 0.9935  Non0_F1_score: 0.9935  Mult_acc_5: 0.8731  Mult_acc_7: 0.8396  MAE: 0.1615  Corr: 0.9907 
2024-11-22 17:16:15:INFO:VAL-(False) >>  Has0_acc_2: 0.8122  Has0_F1_score: 0.8141  Non0_acc_2: 0.8519  Non0_F1_score: 0.8526  Mult_acc_5: 0.4803  Mult_acc_7: 0.4061  MAE: 0.7454  Corr: 0.8011  Loss: 1.0485 
2024-11-22 17:16:17:INFO:VAL-(False) >>  Has0_acc_2: 0.8076  Has0_F1_score: 0.8077  Non0_acc_2: 0.8232  Non0_F1_score: 0.8239  Mult_acc_5: 0.4810  Mult_acc_7: 0.4286  MAE: 0.7476  Corr: 0.7950  Loss: 1.0088 
2024-11-22 17:16:17:INFO:Results are added to results_copy/results\normals\mosi-regression.csv...
2024-11-22 17:24:59:INFO:Start running misa...
2024-11-22 17:24:59:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'mosei', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\MOSEI/Processed/unaligned_50.pkl', 'seq_lens': (50, 500, 375), 'feature_dims': (768, 74, 35), 'train_samples': 10620, 'num_classes': 3, 'language': 'en', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.5, 'reverse_grad_weight': 0.8, 'diff_weight': 0.3, 'sim_weight': 0.8, 'sp_weight': 1.0, 'recon_weight': 1.0, 'grad_clip': 0.8, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-uncased', 'seed': 1111}>
2024-11-22 17:24:59:INFO:Let's use 1 GPUs!
2024-11-22 17:27:04:INFO:train samples: (16326,)
2024-11-22 17:28:33:INFO:valid samples: (1871,)
2024-11-22 17:30:05:INFO:test samples: (4659,)
2024-11-22 17:30:07:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 17:30:08:DEBUG:https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 17:30:09:DEBUG:https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:30:09:DEBUG:https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/config.json HTTP/11" 200 0
2024-11-22 17:30:33:INFO:The model has 110917345 trainable parameters
2024-11-22 17:32:17:INFO:TRAIN-(False) [1/1/False] >> loss: 1.946  Has0_acc_2: 0.7611  Has0_F1_score: 0.7667  Non0_acc_2: 0.7840  Non0_F1_score: 0.7828  Mult_acc_5: 0.4626  Mult_acc_7: 0.4557  MAE: 0.6759  Corr: 0.6080 
2024-11-22 17:32:21:INFO:VAL-(False) >>  Has0_acc_2: 0.8274  Has0_F1_score: 0.8257  Non0_acc_2: 0.8282  Non0_F1_score: 0.8229  Mult_acc_5: 0.4832  Mult_acc_7: 0.4719  MAE: 0.5817  Corr: 0.6981  Loss: 0.5750 
2024-11-22 17:33:59:INFO:TRAIN-(False) [1/2/False] >> loss: 0.8914  Has0_acc_2: 0.8228  Has0_F1_score: 0.8272  Non0_acc_2: 0.8637  Non0_F1_score: 0.8631  Mult_acc_5: 0.5566  Mult_acc_7: 0.5353  MAE: 0.5245  Corr: 0.7960 
2024-11-22 17:34:02:INFO:VAL-(False) >>  Has0_acc_2: 0.8509  Has0_F1_score: 0.8409  Non0_acc_2: 0.8282  Non0_F1_score: 0.8161  Mult_acc_5: 0.4003  Mult_acc_7: 0.3827  MAE: 0.6833  Corr: 0.7430  Loss: 0.7138 
2024-11-22 17:35:33:INFO:TRAIN-(False) [2/3/False] >> loss: 0.5526  Has0_acc_2: 0.8498  Has0_F1_score: 0.8538  Non0_acc_2: 0.8986  Non0_F1_score: 0.8984  Mult_acc_5: 0.6168  Mult_acc_7: 0.5907  MAE: 0.4451  Corr: 0.8601 
2024-11-22 17:35:37:INFO:VAL-(False) >>  Has0_acc_2: 0.8220  Has0_F1_score: 0.8265  Non0_acc_2: 0.8519  Non0_F1_score: 0.8511  Mult_acc_5: 0.4981  Mult_acc_7: 0.4768  MAE: 0.6042  Corr: 0.7429  Loss: 0.6210 
2024-11-22 17:37:10:INFO:TRAIN-(False) [3/4/False] >> loss: 0.3547  Has0_acc_2: 0.8667  Has0_F1_score: 0.8705  Non0_acc_2: 0.9266  Non0_F1_score: 0.9265  Mult_acc_5: 0.6808  Mult_acc_7: 0.6530  MAE: 0.3733  Corr: 0.9048 
2024-11-22 17:37:13:INFO:VAL-(False) >>  Has0_acc_2: 0.7750  Has0_F1_score: 0.7864  Non0_acc_2: 0.8359  Non0_F1_score: 0.8384  Mult_acc_5: 0.5174  Mult_acc_7: 0.5024  MAE: 0.5660  Corr: 0.7286  Loss: 0.5555 
2024-11-22 17:38:51:INFO:TRAIN-(False) [1/5/False] >> loss: 0.2566  Has0_acc_2: 0.8740  Has0_F1_score: 0.8778  Non0_acc_2: 0.9413  Non0_F1_score: 0.9413  Mult_acc_5: 0.7321  Mult_acc_7: 0.7040  MAE: 0.3223  Corr: 0.9297 
2024-11-22 17:38:55:INFO:VAL-(False) >>  Has0_acc_2: 0.8402  Has0_F1_score: 0.8392  Non0_acc_2: 0.8442  Non0_F1_score: 0.8400  Mult_acc_5: 0.4939  Mult_acc_7: 0.4762  MAE: 0.5964  Corr: 0.7354  Loss: 0.5888 
2024-11-22 17:40:30:INFO:TRAIN-(False) [2/6/False] >> loss: 0.2008  Has0_acc_2: 0.8754  Has0_F1_score: 0.8793  Non0_acc_2: 0.9506  Non0_F1_score: 0.9505  Mult_acc_5: 0.7634  Mult_acc_7: 0.7357  MAE: 0.2879  Corr: 0.9452 
2024-11-22 17:40:34:INFO:VAL-(False) >>  Has0_acc_2: 0.8215  Has0_F1_score: 0.8248  Non0_acc_2: 0.8414  Non0_F1_score: 0.8399  Mult_acc_5: 0.5077  Mult_acc_7: 0.4906  MAE: 0.5845  Corr: 0.7327  Loss: 0.5752 
2024-11-22 17:42:09:INFO:TRAIN-(False) [3/7/False] >> loss: 0.1621  Has0_acc_2: 0.8848  Has0_F1_score: 0.8885  Non0_acc_2: 0.9605  Non0_F1_score: 0.9605  Mult_acc_5: 0.7950  Mult_acc_7: 0.7690  MAE: 0.2565  Corr: 0.9565 
2024-11-22 17:42:13:INFO:VAL-(False) >>  Has0_acc_2: 0.7696  Has0_F1_score: 0.7816  Non0_acc_2: 0.8338  Non0_F1_score: 0.8365  Mult_acc_5: 0.5297  Mult_acc_7: 0.5131  MAE: 0.5683  Corr: 0.7318  Loss: 0.5666 
2024-11-22 17:43:47:INFO:TRAIN-(False) [4/8/False] >> loss: 0.1469  Has0_acc_2: 0.8839  Has0_F1_score: 0.8877  Non0_acc_2: 0.9646  Non0_F1_score: 0.9646  Mult_acc_5: 0.8091  Mult_acc_7: 0.7838  MAE: 0.2448  Corr: 0.9605 
2024-11-22 17:43:50:INFO:VAL-(False) >>  Has0_acc_2: 0.8113  Has0_F1_score: 0.8179  Non0_acc_2: 0.8477  Non0_F1_score: 0.8481  Mult_acc_5: 0.5361  Mult_acc_7: 0.5190  MAE: 0.5407  Corr: 0.7390  Loss: 0.5102 
2024-11-22 17:45:26:INFO:TRAIN-(False) [1/9/False] >> loss: 0.1302  Has0_acc_2: 0.8909  Has0_F1_score: 0.8944  Non0_acc_2: 0.9722  Non0_F1_score: 0.9722  Mult_acc_5: 0.8220  Mult_acc_7: 0.7985  MAE: 0.2249  Corr: 0.9655 
2024-11-22 17:45:30:INFO:VAL-(False) >>  Has0_acc_2: 0.7060  Has0_F1_score: 0.7223  Non0_acc_2: 0.7928  Non0_F1_score: 0.7974  Mult_acc_5: 0.5131  Mult_acc_7: 0.4976  MAE: 0.6002  Corr: 0.7322  Loss: 0.6205 
2024-11-22 17:47:03:INFO:TRAIN-(False) [2/10/False] >> loss: 0.1229  Has0_acc_2: 0.8883  Has0_F1_score: 0.8920  Non0_acc_2: 0.9739  Non0_F1_score: 0.9739  Mult_acc_5: 0.8321  Mult_acc_7: 0.8086  MAE: 0.2201  Corr: 0.9675 
2024-11-22 17:47:06:INFO:VAL-(False) >>  Has0_acc_2: 0.8161  Has0_F1_score: 0.8208  Non0_acc_2: 0.8428  Non0_F1_score: 0.8420  Mult_acc_5: 0.5211  Mult_acc_7: 0.5067  MAE: 0.5515  Corr: 0.7355  Loss: 0.5225 
2024-11-22 17:48:38:INFO:TRAIN-(False) [3/11/False] >> loss: 0.1116  Has0_acc_2: 0.8953  Has0_F1_score: 0.8987  Non0_acc_2: 0.9789  Non0_F1_score: 0.9789  Mult_acc_5: 0.8433  Mult_acc_7: 0.8205  MAE: 0.2095  Corr: 0.9706 
2024-11-22 17:48:41:INFO:VAL-(False) >>  Has0_acc_2: 0.8113  Has0_F1_score: 0.8179  Non0_acc_2: 0.8449  Non0_F1_score: 0.8454  Mult_acc_5: 0.5361  Mult_acc_7: 0.5216  MAE: 0.5518  Corr: 0.7372  Loss: 0.5490 
2024-11-22 17:50:13:INFO:TRAIN-(False) [4/12/False] >> loss: 0.1062  Has0_acc_2: 0.8989  Has0_F1_score: 0.9022  Non0_acc_2: 0.9828  Non0_F1_score: 0.9828  Mult_acc_5: 0.8553  Mult_acc_7: 0.8316  MAE: 0.1982  Corr: 0.9731 
2024-11-22 17:50:16:INFO:VAL-(False) >>  Has0_acc_2: 0.8167  Has0_F1_score: 0.8213  Non0_acc_2: 0.8435  Non0_F1_score: 0.8427  Mult_acc_5: 0.5393  Mult_acc_7: 0.5243  MAE: 0.5500  Corr: 0.7380  Loss: 0.5363 
2024-11-22 17:51:48:INFO:TRAIN-(False) [5/13/False] >> loss: 0.0951  Has0_acc_2: 0.9004  Has0_F1_score: 0.9038  Non0_acc_2: 0.9895  Non0_F1_score: 0.9895  Mult_acc_5: 0.8729  Mult_acc_7: 0.8518  MAE: 0.1821  Corr: 0.9770 
2024-11-22 17:51:52:INFO:VAL-(False) >>  Has0_acc_2: 0.8279  Has0_F1_score: 0.8310  Non0_acc_2: 0.8505  Non0_F1_score: 0.8489  Mult_acc_5: 0.5297  Mult_acc_7: 0.5115  MAE: 0.5638  Corr: 0.7414  Loss: 0.5484 
2024-11-22 17:53:23:INFO:TRAIN-(False) [6/14/False] >> loss: 0.0925  Has0_acc_2: 0.9016  Has0_F1_score: 0.9049  Non0_acc_2: 0.9912  Non0_F1_score: 0.9912  Mult_acc_5: 0.8716  Mult_acc_7: 0.8508  MAE: 0.1761  Corr: 0.9785 
2024-11-22 17:53:27:INFO:VAL-(False) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.8038  Non0_acc_2: 0.8484  Non0_F1_score: 0.8497  Mult_acc_5: 0.5387  Mult_acc_7: 0.5211  MAE: 0.5429  Corr: 0.7426  Loss: 0.5063 
2024-11-22 17:54:59:INFO:TRAIN-(False) [1/15/False] >> loss: 0.0938  Has0_acc_2: 0.9002  Has0_F1_score: 0.9035  Non0_acc_2: 0.9917  Non0_F1_score: 0.9917  Mult_acc_5: 0.8705  Mult_acc_7: 0.8470  MAE: 0.1770  Corr: 0.9783 
2024-11-22 17:55:03:INFO:VAL-(False) >>  Has0_acc_2: 0.8012  Has0_F1_score: 0.8090  Non0_acc_2: 0.8463  Non0_F1_score: 0.8471  Mult_acc_5: 0.5366  Mult_acc_7: 0.5216  MAE: 0.5327  Corr: 0.7427  Loss: 0.4910 
2024-11-22 17:56:36:INFO:TRAIN-(False) [1/16/False] >> loss: 0.0937  Has0_acc_2: 0.8976  Has0_F1_score: 0.9011  Non0_acc_2: 0.9918  Non0_F1_score: 0.9918  Mult_acc_5: 0.8733  Mult_acc_7: 0.8520  MAE: 0.1750  Corr: 0.9788 
2024-11-22 17:56:39:INFO:VAL-(False) >>  Has0_acc_2: 0.8300  Has0_F1_score: 0.8314  Non0_acc_2: 0.8414  Non0_F1_score: 0.8388  Mult_acc_5: 0.5232  Mult_acc_7: 0.5061  MAE: 0.5667  Corr: 0.7415  Loss: 0.5426 
2024-11-22 17:58:12:INFO:TRAIN-(False) [2/17/False] >> loss: 0.0928  Has0_acc_2: 0.8989  Has0_F1_score: 0.9024  Non0_acc_2: 0.9911  Non0_F1_score: 0.9911  Mult_acc_5: 0.8806  Mult_acc_7: 0.8610  MAE: 0.1701  Corr: 0.9798 
2024-11-22 17:58:16:INFO:VAL-(False) >>  Has0_acc_2: 0.7878  Has0_F1_score: 0.7974  Non0_acc_2: 0.8408  Non0_F1_score: 0.8423  Mult_acc_5: 0.5361  Mult_acc_7: 0.5200  MAE: 0.5394  Corr: 0.7382  Loss: 0.5059 
2024-11-22 17:59:48:INFO:TRAIN-(False) [3/18/False] >> loss: 0.0942  Has0_acc_2: 0.9021  Has0_F1_score: 0.9054  Non0_acc_2: 0.9905  Non0_F1_score: 0.9905  Mult_acc_5: 0.8750  Mult_acc_7: 0.8559  MAE: 0.1744  Corr: 0.9791 
2024-11-22 17:59:52:INFO:VAL-(False) >>  Has0_acc_2: 0.7990  Has0_F1_score: 0.8067  Non0_acc_2: 0.8428  Non0_F1_score: 0.8434  Mult_acc_5: 0.5393  Mult_acc_7: 0.5227  MAE: 0.5364  Corr: 0.7367  Loss: 0.5065 
2024-11-22 18:01:24:INFO:TRAIN-(False) [4/19/False] >> loss: 0.0916  Has0_acc_2: 0.9030  Has0_F1_score: 0.9062  Non0_acc_2: 0.9923  Non0_F1_score: 0.9923  Mult_acc_5: 0.8823  Mult_acc_7: 0.8624  MAE: 0.1682  Corr: 0.9805 
2024-11-22 18:01:28:INFO:VAL-(False) >>  Has0_acc_2: 0.8087  Has0_F1_score: 0.8150  Non0_acc_2: 0.8449  Non0_F1_score: 0.8450  Mult_acc_5: 0.5318  Mult_acc_7: 0.5158  MAE: 0.5408  Corr: 0.7410  Loss: 0.5065 
2024-11-22 18:03:00:INFO:TRAIN-(False) [5/20/False] >> loss: 0.0871  Has0_acc_2: 0.9003  Has0_F1_score: 0.9038  Non0_acc_2: 0.9939  Non0_F1_score: 0.9939  Mult_acc_5: 0.8927  Mult_acc_7: 0.8731  MAE: 0.1581  Corr: 0.9823 
2024-11-22 18:03:04:INFO:VAL-(False) >>  Has0_acc_2: 0.7948  Has0_F1_score: 0.8038  Non0_acc_2: 0.8463  Non0_F1_score: 0.8477  Mult_acc_5: 0.5366  Mult_acc_7: 0.5190  MAE: 0.5416  Corr: 0.7405  Loss: 0.5032 
2024-11-22 18:04:36:INFO:TRAIN-(False) [6/21/False] >> loss: 0.09  Has0_acc_2: 0.9005  Has0_F1_score: 0.9039  Non0_acc_2: 0.9937  Non0_F1_score: 0.9937  Mult_acc_5: 0.8814  Mult_acc_7: 0.8597  MAE: 0.1666  Corr: 0.9808 
2024-11-22 18:04:40:INFO:VAL-(False) >>  Has0_acc_2: 0.8156  Has0_F1_score: 0.8215  Non0_acc_2: 0.8505  Non0_F1_score: 0.8505  Mult_acc_5: 0.5425  Mult_acc_7: 0.5265  MAE: 0.5390  Corr: 0.7358  Loss: 0.5033 
2024-11-22 18:06:13:INFO:TRAIN-(False) [7/22/False] >> loss: 0.0874  Has0_acc_2: 0.9010  Has0_F1_score: 0.9044  Non0_acc_2: 0.9935  Non0_F1_score: 0.9935  Mult_acc_5: 0.8869  Mult_acc_7: 0.8688  MAE: 0.1611  Corr: 0.9818 
2024-11-22 18:06:16:INFO:VAL-(False) >>  Has0_acc_2: 0.8156  Has0_F1_score: 0.8219  Non0_acc_2: 0.8505  Non0_F1_score: 0.8509  Mult_acc_5: 0.5404  Mult_acc_7: 0.5216  MAE: 0.5365  Corr: 0.7462  Loss: 0.4991 
2024-11-22 18:07:49:INFO:TRAIN-(False) [8/23/False] >> loss: 0.0871  Has0_acc_2: 0.9021  Has0_F1_score: 0.9054  Non0_acc_2: 0.9938  Non0_F1_score: 0.9938  Mult_acc_5: 0.8890  Mult_acc_7: 0.8698  MAE: 0.1583  Corr: 0.9823 
2024-11-22 18:07:53:INFO:VAL-(False) >>  Has0_acc_2: 0.8300  Has0_F1_score: 0.8329  Non0_acc_2: 0.8470  Non0_F1_score: 0.8456  Mult_acc_5: 0.5265  Mult_acc_7: 0.5104  MAE: 0.5381  Corr: 0.7414  Loss: 0.4923 
2024-11-22 18:08:03:INFO:VAL-(False) >>  Has0_acc_2: 0.7961  Has0_F1_score: 0.8034  Non0_acc_2: 0.8440  Non0_F1_score: 0.8449  Mult_acc_5: 0.5383  Mult_acc_7: 0.5211  MAE: 0.5489  Corr: 0.7612  Loss: 0.5282 
2024-11-22 18:08:03:INFO:Results are added to results_copy/results\normals\mosei-regression.csv...
2024-11-22 21:51:48:INFO:Start running misa...
2024-11-22 21:51:48:INFO:<Storage{'is_tune': False, 'train_mode': 'regression', 'modelName': 'misa', 'datasetName': 'sims', 'num_workers': 0, 'model_save_dir': 'results_copy/models', 'res_save_dir': 'results_copy/results\\normals', 'gpu_ids': [0], 'seeds': [1111], 'dataPath': 'E:\\yanyi\\code of paper\\MISA-master\\MISA-master\\Dataset\\SIMS/unaligned_39.pkl', 'seq_lens': (39, 400, 55), 'feature_dims': (768, 33, 709), 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'need_data_aligned': False, 'need_model_aligned': False, 'need_normalized': False, 'use_bert': True, 'use_finetune': True, 'save_labels': False, 'early_stop': 8, 'update_epochs': 4, 'rnncell': 'lstm', 'use_cmd_sim': True, 'batch_size': 64, 'learning_rate': 0.0001, 'hidden_size': 128, 'dropout': 0.0, 'reverse_grad_weight': 0.5, 'diff_weight': 0.3, 'sim_weight': 1.0, 'sp_weight': 1.0, 'recon_weight': 0.8, 'grad_clip': 1.0, 'weight_decay': 5e-05, 'transformers': 'bert', 'pretrained': 'bert-base-chinese', 'seed': 1111}>
2024-11-22 21:51:48:INFO:Let's use 1 GPUs!
2024-11-22 21:51:55:INFO:train samples: (1368,)
2024-11-22 21:51:55:INFO:valid samples: (456,)
2024-11-22 21:51:56:INFO:test samples: (457,)
2024-11-22 21:51:56:DEBUG:Starting new HTTPS connection (1): huggingface.co:443
2024-11-22 21:52:05:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/tokenizer_config.json HTTP/11" 200 0
2024-11-22 21:52:06:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 21:52:06:DEBUG:https://huggingface.co:443 "HEAD /bert-base-chinese/resolve/main/config.json HTTP/11" 200 0
2024-11-22 21:52:08:INFO:The model has 123932397 trainable parameters
2024-11-22 21:52:16:INFO:TRAIN-(False) [1/1/False] >> loss: 2.6104  Mult_acc_2: 0.6148  Mult_acc_3: 0.4898  Mult_acc_5: 0.2010  F1_score: 0.5856  MAE: 0.6129  Corr: 0.0667 
2024-11-22 21:52:17:INFO:VAL-(False) >>  Mult_acc_2: 0.6952  Mult_acc_3: 0.5439  Mult_acc_5: 0.2193  F1_score: 0.5780  MAE: 0.5632  Corr: 0.3361  Loss: 0.4383 
